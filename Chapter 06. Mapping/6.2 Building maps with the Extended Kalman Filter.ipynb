{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Building maps with the Extended Kalman Filter - The Nirvana shopping mall\n",
    "\n",
    "The managers behind the **<span style=\"color:seagreen\">Nirvana shopping mall</span>**, in the scope of their *experiencing the future* plan, have contacted **<span style=\"color:seagreen\">UMA-MR</span>** (our brand-new mobile robotics company at UMA) looking for mobile robots able to guide their visitors between different points of interest in their facilities, like information points, the entrance to relevant (paying well) shops, rescue points, etc. \n",
    "\n",
    "<br /><br />\n",
    "<center>\n",
    "<img src=\"./images/nirvana-logo.png\" width=\"600\">\n",
    "</center>\n",
    "<br />\n",
    "\n",
    "These managers have placed identifying marks close to the points of interest they want to consider, but do not know their exact location in the mall. **Our mission as engineers at *UMA-MR* is to build a map of the mall containing such points, so the robot can operate within it.** We are going to use for that an **Extended Kalman Filter (EKF)**.\n",
    "\n",
    "Fortunately, our company has developed a system able to provide the exact location of our robots at each time instant, which are also equipped with a range-and-bearing nosiy sensor able to detect the identifying marks and take measurements to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Formalizing the problem\n",
    "\n",
    "Since we are going to build a map of $N$ landmarks, the position of those landmarks in the map $m$ are the random variables to be estimated. In this way, the state vector in the mapping case is defined as:\n",
    "\n",
    "$$m = [m_1, m_2, \\cdots, m_N] = \n",
    "[x_1, y_1, \\underbrace{x_2, y_2}_{\\text{Position of}\\\\\\text{landmark 2}}, \\dots,x_N, y_N]^T, \\ \\ \\ len(m) = 2N$$\n",
    "\n",
    "In other words, we pursuit the estimation of the probability distribution:\n",
    "\n",
    "$$p(m | z_{1:t}, x_{1:t})$$\n",
    "\n",
    "being $z_{1:t}$ the sensor measurements taken until time instant $t$, and $x_{1:t}$ the robot poses from which those measurements were acquired. Recall that a sensor measurement is related to the pose $x$ and the map $m$ by means of the **observation function**:\n",
    "\n",
    "$$z = h(x,m) + e \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, e \\sim N(0,Q)$$\n",
    "\n",
    "Two assumptions are made when building maps using EFK.\n",
    "\n",
    "#### Assumption 1: each landmark position is estimated independently\n",
    "\n",
    "For simplifying the problem, it is usual to assume that the estimation of the position of the landmarks is independent one to another, only depending each one on its observations, so:\n",
    "\n",
    "$$p(m_i|z_{1:t}, x_{1:t}) = p(m_i |z^i_{1:t}, x_{1:t})$$\n",
    "\n",
    "which results in the following simplification:\n",
    "\n",
    "$$p(m | z_{1:t}, x_{1:t})= p(m_1, m_2, \\cdots, m_N | z_{1:t}, x_{1:t}) = \\prod_{k=1}^N p(m_i | z^i_{1:t}, x_{1:t})$$\n",
    "\n",
    "As a consequence of this, the estimation of, for example, 3 landmarks simultaneously is the same as using three concurrent and independent EKFs for estimating them. \n",
    "\n",
    "#### Assumption 2: the map is static\n",
    "\n",
    "Unlike the localization case, where the robot pose changed over time, in this case it is assumed that the map is static, that is, the landmarks are still. This means that in the state transition model $m_k=m_{k-1}$, that is:\n",
    "\n",
    "$$m_t = A_t m_{t-1} + B_t u_t + \\epsilon_t \\ \\ \\ \\ (A=I, u=0, \\epsilon=0)$$\n",
    "\n",
    "So good news here!, there is no need for a prediction step in the EKF, we only have to model the correction (update) one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Developing the EKF filter for mapping the mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.tcomp import tcomp\n",
    "from utils.AngleWrap import AngleWrap\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.Jacobians import J2\n",
    "from utils.unit6.MapCanvas import MapCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The provided robot\n",
    "\n",
    "Take a look at the following ``EFKMappingRobot()`` class, which is already provided by your colleagues at **<span style=\"color:seagreen\">UMA-MR</span>**, modeling **a robot equipped with a range and bearing sensor**, which is able to keep the following information:\n",
    "- ``true_pose``: The exact pose of the robot in the environment, which is perfectly known.\n",
    "- ``Q``: Uncertainty of the range and bearing sensor, which has the form:\n",
    "$\\Sigma_{r\\theta} = \\begin{bmatrix} \\sigma^2_r & 0 \\\\ 0 & \\sigma^2_\\theta  \\end{bmatrix}$\n",
    "- ``xEst``: Vector with the estimated state, in this case the position of the $M$ observed landmarks: $[x_1, y_1, x_2, y_2, \\dots,x_M, y_M]^T$. Its size changes over time with the detection of previously unobserved landmarks.\n",
    "- ``PEst``: uncertainty associated with those predictions, with size ($M\\times2$,$M\\times2$). Its size also changes over time.\n",
    "- ``MappedLandmarks``: A vector with length equal to the number of landmarks in the map ($N$), which elements can take the following values:\n",
    "  - ``-1`` if the landmark with that index has not been seen yet.\n",
    "  - ``idx_in_xEst``: an odd number indicating the position of that landmark in ``xEst``.\n",
    "  For example, if during the robot operation in a map with 5 landmarks, it first detect the landmark with id 2, and later the one with id 4, the content of this vector would be ``MappedLandmarks=[-1,-1,1,-1,3]``.\n",
    "\n",
    "and to perform the following actions:\n",
    "\n",
    "- ``step()``: Performs a motion command, without noise. \n",
    "- ``observe()``: Returns a range and bearing measurement (in polars) to a given landmark in the map.\n",
    "- ``get_random_observation()``: Returns a range and bearing measurement (in polars) to a random landmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFKMappingRobot():\n",
    "    def __init__(self, true_pose, sigma_r, sigma_theta, n_features):\n",
    "        # Robot description\n",
    "        self.true_pose = true_pose\n",
    "        self.Q = np.diag([sigma_r, sigma_theta])**2\n",
    "        \n",
    "        # Map -- Initially empty\n",
    "        self.xEst = np.empty((0, 0))\n",
    "        self.PEst = np.empty((0, 0))\n",
    "        self.QEst = 1.0*self.Q\n",
    "        \n",
    "        self.MappedLandmarks = -1*np.ones((n_features,1), int)\n",
    "        \n",
    "    def step(self, u):\n",
    "        self.true_pose = tcomp(self.true_pose, u)\n",
    "        \n",
    "    def observe(self, idx, world, noisy=True):\n",
    "        \"\"\" Generate a observation of a feature in our world\n",
    "        \n",
    "            Args:\n",
    "                world: Complete map of all landmarks in the world\n",
    "                idx: Landmark to observe (index in world matrix)\n",
    "                noisy: Add noise to z, prorportional to self.Q\n",
    "                \n",
    "            Returns:\n",
    "                z: One range and bearing observation\n",
    "        \"\"\"\n",
    "        \n",
    "        z = np.empty((2, 1))\n",
    "        delta = world[:, [idx]] - self.true_pose[0:2, :]\n",
    "        \n",
    "        # Range\n",
    "        # z[0, :] = np.sqrt(np.sum(delta**2)) # OVERFLOW HERE??\n",
    "        z[0, :] = np.sqrt(np.sum(np.power(delta, 2))) # np.power???\n",
    "    \n",
    "        # Bearing\n",
    "        z[1, :] = np.arctan2(delta[1, 0],delta[0, 0]) - self.true_pose[2, 0]\n",
    "        z[1, :] = AngleWrap(z[1, :])\n",
    "        \n",
    "        if noisy:\n",
    "            z = z + np.sqrt(self.Q)@random.randn(2,1)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def get_random_observation(self, world, noisy=True):\n",
    "        iLandmarks = world.shape[1]\n",
    "        iLandmark = random.randint(iLandmarks)\n",
    "        z = self.observe(iLandmark, world, noisy)\n",
    "        return z, [iLandmark]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction step\n",
    "\n",
    "As commented, the map is considered static, so the prediction step is reduced to consider as the predicted landmarks' positions the ones estimated in the previous step. The same holds for the predicted uncertainty, so this steps results in something like this:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}\n",
    "       \\verb!def !& \\verb!ExtendedKalmanFilter!(m_{t-1},\\Sigma_{t-1}, z_t): \\\\\n",
    "      & \\textbf{Prediction.} \\\\\n",
    "      & \\bar m_t = m_{t-1} &\\text{(1. Map prediction)}\\\\\n",
    "      & \\bar\\Sigma_t = \\Sigma_{t-1} &\\text{(2. Uncertainty of prediction)}\\\\      \n",
    "  \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Implementing the naive prediction step</i></b></span>** \n",
    "\n",
    "**You are tasked to** implement the previous behavior in the following function, which performs the prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_step(robot: EFKMappingRobot): \n",
    "    \"\"\" Performs the prediction step of the EKF algorithm for mapping\n",
    "            robot: Robot base (contains state map: xEst, PEst)\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "            xPred: Predicted position of the landmarks\n",
    "            PPred: Predicted uncertainty of the landmarks positions\n",
    "    \"\"\"    \n",
    "    \n",
    "    # We assume that the map is static \n",
    "    xPred = robot.xEst\n",
    "    # robot.PEst: Uncertainty of the landmark positions at t-1\n",
    "    PPred = robot.PEst\n",
    "    \n",
    "    return xPred, PPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **test your function** with the next code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xPred:\n",
      "[[0.5]\n",
      " [0.7]]\n",
      "PPred:\n",
      "[[1.32 0.  ]\n",
      " [0.   0.8 ]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "xVehicleTrue = np.vstack([0.5, 0.7, 0]) # We know the exact robot pose at any moment!\n",
    "robot = EFKMappingRobot(xVehicleTrue, 1, 0.8, 1)\n",
    "robot.xEst = np.vstack([.5, .7])\n",
    "robot.PEst = np.diag([1.32, 0.8])\n",
    "[xPred,PPred] = prediction_step(robot)\n",
    "print('xPred:\\n' + str(xPred))\n",
    "print('PPred:\\n' + str(PPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "xPred:\n",
    "[[0.5]\n",
    " [0.7]]\n",
    "PPred:\n",
    "[[1.32 0.  ]\n",
    " [0.   0.8 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing a landmark for first time\n",
    "\n",
    "When the sensor onboard the robot detects a landmark for the first time, there is no need to do the EKF update step (indeed, since there is not previously knowledge about the landmark, there is nothing to update). Instead, we have to properly modify 1) the vector of estimated landmark positions, and 2) their associated uncertainties, to accommodate this new information:\n",
    "\n",
    "\n",
    "1. **Modifying the state vector**: Insert the position of the new observed landmark $[x_{M+1},y_{M+1}]$, using the sensor measurement $z_k=[r_k,\\theta_k]$, at the end of the vector containing the estimated positions ``xEst``, so: $\\\\[10pt]$\n",
    "$$xEst=[x_1,y_y, \\cdots, x_M, y_M, x_{M+1}, y_{M+1}]\\\\[5pt]$$ \n",
    "Since the measurment is provided in polar coordinates in the robot local frame, we have to convert them first to cartensians and then to the world frame using the robot pose $[x_v,y_v]'$. The function in charge of doing so can be defined as:\n",
    "\n",
    "$$ \n",
    "f(x_v,z_k)=\\begin{bmatrix} x_{M+1} \\\\ y_{M+1} \\end{bmatrix} =\n",
    "\\begin{bmatrix} x_v \\\\ y_v \\end{bmatrix} + \n",
    "r_k\\begin{bmatrix} cos \\alpha_k \\\\ sin \\alpha_k \\end{bmatrix}\n",
    ", \\ \\ \\alpha_k = \\theta_k + \\theta_v\n",
    "$$\n",
    "\n",
    "2. **Extending the covariance matrix**. In order to acomodate the uncertainty regarding the position of the new landmark, we have to extend the covariance matrix in the following way: $\\\\[10pt]$\n",
    "$$\n",
    "PEst=\\begin{bmatrix}\n",
    "    [\\Sigma^1_{xy}]_{2 \\times 2} & \\cdots & 0_{2 \\times 2} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    0_{2 \\times 2} & \\cdots & [\\Sigma^{M+1}_{xy}]_{2 \\times 2}\n",
    "  \\end{bmatrix}_{2n \\times 2n}\n",
    "  $$  \n",
    "Notice that the covariance $\\Sigma^{M+1}_{xy}$ stands for the uncertainty in the measurement expressed in the world cartesian coordinates, retrieved by: $\\\\[10pt]$\n",
    "$$\\Sigma^{M+1}_{xy} = J \\Sigma^{M+1}_{r\\theta} J^T \\\\[5pt]$$ \n",
    "being $\\Sigma^{M+1}_{r\\theta}$ the uncertainty characterizing the sensor measurements (``QEst`` in our code), and $J$ (``jGz`` in our code) the jacobian of the function $f(x_v,z_k)$ that expresses the measurement in global coordinates, which is: $\\\\[10pt]$\n",
    "$$\n",
    "J =  \\begin{bmatrix} \\partial x / \\partial r  &  \\partial x / \\partial \\theta \\\\ \\partial y / \\partial r & \\partial y / \\partial \\theta \\end{bmatrix} =\n",
    "\\begin{bmatrix} cos \\alpha & -r sin \\alpha \\\\ sin \\alpha & r cos \\alpha \\end{bmatrix} \\\\[10pt]\n",
    "$$\n",
    "Notice that this jacobian is the result of concatenating both, the jacobian of the composition of a pose and a landmark, and the jacobian of the function transforming polar into cartesian coordinates. It is quite similar to the one just transforming polar into cartesian, but in this case the angle  𝛼  is the sum of the robot orientation and the measured angle (bearing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Incorporating a landmark detected for first time</i></b></span>** \n",
    "\n",
    "**Your work here is to:**\n",
    "- Complete the ``get_new_landmark_jacobians()`` to compute the jacobian $J$.\n",
    "- Complete the ``incorporate_new_landmark()`` method to modify the state vector ``xEst`` and the convariance matrix ``PEst`` as explained above. We will make use of the [`linalg.block_diag()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.block_diag.html) function at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_landmark_jacobians(Xv, z):\n",
    "    \"\"\" Calculate the jacobian for transforming an observation to the world frame\n",
    "    \n",
    "        Args:\n",
    "            Xv: True pose of our robot\n",
    "            z: Observation of a landmark. In polar coordinates from the p.o.v. of our robot.\n",
    "        \n",
    "        Returns:\n",
    "            2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    # z is a column vector\n",
    "    r, a = z[0,0], z[1,0]+Xv[2,0]\n",
    "    c, s = np.cos(a), np.sin(a)\n",
    "    jGz = np.array([\n",
    "        [c, -r*s],\n",
    "        [s, r*c]\n",
    "    ])\n",
    "    return jGz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it working properly? **Try it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jGz:\n",
      "[[ 0.93937271 -0.41147737]\n",
      " [ 0.34289781  1.12724726]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "z = np.vstack([1.2,0.35])\n",
    "Xv = np.vstack([2, 2.1, 0])\n",
    "jGz = get_new_landmark_jacobians(Xv, z)\n",
    "print('jGz:\\n' + str(jGz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "jGz:\n",
    "[[ 0.93937271 -0.41147737]\n",
    " [ 0.34289781  1.12724726]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorporate_new_landmark(robot: EFKMappingRobot, z, iLandmark, xPred, PPred):\n",
    "    \"\"\" Incorporates the information relative to a new ladmark to our system\n",
    "        robot: Robot base (contains state map: xEst, PEst)\n",
    "        z: Observation of a landmark\n",
    "        iLandmark: Index of z in the world map\n",
    "        xPred: Predicted map\n",
    "        PPred: Uncertainty of the prediction\n",
    "\n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    # This is a new feature, so add it to the map        \n",
    "        \n",
    "    # The observation is in the local frame of the robot, it has to\n",
    "    # be translated to the global frame\n",
    "    a = robot.true_pose[2,0] + z[1,0]\n",
    "    r, s, c = z[0,0], np.sin(a), np.cos(a)\n",
    "    xLandmark = np.array([[robot.true_pose[0,0] + r*c],\n",
    "                          [robot.true_pose[1,0] + r*s]])\n",
    "\n",
    "    # Add it to the current state\n",
    "    nStates = xPred.size \n",
    "        \n",
    "    if nStates == 0:\n",
    "        robot.xEst = xLandmark\n",
    "    else:\n",
    "        robot.xEst = np.vstack([robot.xEst, xLandmark]) #Each new feature two new rows\n",
    "\n",
    "    # Compute the jacobian\n",
    "    jGz = get_new_landmark_jacobians(robot.true_pose, z) #Dimension 2x2\n",
    "    \n",
    "    # Build a matrix M incorporating the jacobian to multiply the extendend PEst matrix by it (see below)\n",
    "    if nStates != 0:\n",
    "        # note we don't use jacobian w.r.t vehicle since the pose doesn’t have uncertainty\n",
    "        M = np.vstack([  \n",
    "                np.hstack([jGz, np.zeros((nStates, 2))]),\n",
    "                np.hstack([np.zeros((2, nStates)), jGz])\n",
    "            ])\n",
    "    else: \n",
    "        # First landmark observed!\n",
    "        M = jGz\n",
    "\n",
    "    # Hago la otra forma indicada por el profesor en el comentario de abajo\n",
    "    new_sigma_wc = jGz@ robot.QEst @jGz.T\n",
    "    robot.PEst = linalg.block_diag(robot.PEst, new_sigma_wc)\n",
    "    # robot.PEst = M@linalg.block_diag(None, PPred)@M.T\n",
    "\n",
    "    #This can also be done directly PEst = [PEst,zeros(nStates,2);\n",
    "                                            # zeros(2,nStates),\n",
    "                                            # jGz*QEst*jGz']\n",
    "\n",
    "    #remember this landmark as being mapped: we store its ID for the state vector\n",
    "    robot.MappedLandmarks[iLandmark] = robot.xEst.size-2 #Always an odd number\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The correction (update) step\n",
    "\n",
    "Once a landmark has been detected and its provided information (location and uncertainty) has been properly incorporated to our mapping system, such an information can be updated with new measurements of such a landmark. For doing so, the EKF algorithm performs the following steps:\n",
    "\n",
    "$$\n",
    "  \\begin{aligned}     \n",
    "      & \\textbf{Correction.} \\\\\n",
    "      & K_t = \\bar\\Sigma_t H^T_t (H_t \\bar\\Sigma_t H^T_t + Q_t)^{-1} &\\text{(3. Kalman gain)}\\\\\n",
    "      & m_t = \\bar m_t + K_t (z_t - h(x_t,\\bar m_t)) &\\text{(4. Map estimation)}\\\\\n",
    "      & \\Sigma_t = (I - K_t H_t) \\bar\\Sigma_t &\\text{(5. Uncertainty of estimation)}\\\\\n",
    "      & \\verb!return ! m_t, \\Sigma_t\n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "Notice that the map (landmark locations) is estimated according to the map estimation in the previous time step $t-1$, the *Kalman gain*, and the error (also called ***innovation***) between the obsevation taken by the sensor ($z_t$) and the one computed by the observation model given the robot pose and the predicted map, that is $z_t - h(x_t,\\bar m_t$).\n",
    "\n",
    "In such equations, H (``jH`` in our code) represents the jacobian of the observation model. The shape of such a jacobian is $(2,M\\times2)$, and has the following form:\n",
    "\n",
    "$$\n",
    "H = \\left[\n",
    "  \\begin{matrix}\n",
    "0 & 0 & \\cdots \\\\\n",
    "0 & 0 & \\cdots \\\\\n",
    "\\end{matrix}\n",
    "\\right .\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "jHxl_{11} & jHxl_{12} \\\\\n",
    "jHxl_{21} & jHxl_{22} \\\\\n",
    "\\end{bmatrix}}_\\text{Jacobian for the observed landmark, $jHxl$}\n",
    "\\left .\n",
    "\\begin{matrix}\n",
    "\\cdots & 0 & 0 \\\\\n",
    "\\cdots & 0 & 0 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "jHxl = \n",
    "\\begin{bmatrix}\n",
    "(x_l - x)/d & (y_l - y)/d \\\\\n",
    "-(y_l - y)/d^2 & (x_l - x)/d^2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $[x_l,y_l]$ is the position of the landmark, $[x,y]$ is the robot location, and $d=\\sqrt{(x_l-x)^2 + (y_l-y)^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Updating the knowledge about an observed landmark</i></b></span>** \n",
    "\n",
    "**Your job at this point is:**\n",
    "\n",
    "- To implement the function ``get_observation_jacobian()`` returning the jacobian of the observed landmark, that is, $jHxl$.\n",
    "- To complete the ``update_step()`` method that performs the update step of the EKF algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_jacobian(xPred, xLandmark):\n",
    "    \"\"\" Calculate the jacobian of the observation model.\n",
    "        \n",
    "        Needed to update a landmark we have already seen.\n",
    "        Hint. Similar to the one described in unit 5 (Localization)\n",
    "        \n",
    "        Args:\n",
    "            xPred: True pose of our robot.\n",
    "            xLandmark: Estimated pose of a landmark in our map. World p.o.v in cartesian coordinates.\n",
    "                Does not contain an angle.\n",
    "        \n",
    "        Return:\n",
    "            jHxl: 2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    xdist = xLandmark[0,0] - xPred[0,0]  # NOT CHANGE\n",
    "    ydist = xLandmark[1,0] - xPred[1,0]  # NOT CHANGE\n",
    "    r = np.sqrt(xdist**2 + ydist**2)\n",
    "    r2 = r**2\n",
    "    jHxl = np.array([\n",
    "        [xdist/r , ydist/r],\n",
    "        [-ydist/r2 , xdist/r2]\n",
    "    ])\n",
    "    return jHxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if your implementation is right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jHxl:\n",
      "[[ 0.98058068 -0.19611614]\n",
      " [ 0.38461538  1.92307692]]\n"
     ]
    }
   ],
   "source": [
    "# TRY IT!\n",
    "xLandmark = np.vstack([2.5,2])\n",
    "xPred = np.vstack([2, 2.1, 0])\n",
    "jHxl = get_observation_jacobian(xPred, xLandmark)\n",
    "print('jHxl:\\n' + str(jHxl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "jHxl:\n",
    "[[ 0.98058068 -0.19611614]\n",
    " [ 0.38461538  1.92307692]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(robot, z, iLandmark, xPred, PPred):\n",
    "    \"\"\" Performs the update step of EKF\n",
    "        robot: Robot base (contains state map: xEst, PEst)\n",
    "        z: Observation of a landmark\n",
    "        iLandmark: Index of z in the world map\n",
    "        xPred: Predicted map\n",
    "        PPred: Uncertainty of the prediction\n",
    "        \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    # Find out where it is in state vector\n",
    "    landmarkIndex = robot.MappedLandmarks[iLandmark[0], 0]\n",
    "        \n",
    "    # xLandmark is the current estimation of the position of the\n",
    "    # landmard \"FeatureIndex\"\n",
    "    xLandmark = xPred[landmarkIndex:landmarkIndex+2]\n",
    "        \n",
    "    # DONE Predicts the observation\n",
    "    zPred = robot.observe(0, xLandmark, noisy=False) # Hint: use robot.observe function\n",
    "\n",
    "    # Get observation Jacobians\n",
    "    jHxf = get_observation_jacobian(xPred, zPred)\n",
    "        \n",
    "    # Fill in state jacobian\n",
    "    # (the jacobian is zero except for the observed landmark)\n",
    "    jH = np.zeros((2, xPred.size))\n",
    "    jH[:, landmarkIndex:landmarkIndex+2] = jHxf\n",
    "        \n",
    "    #\n",
    "    # Kalman update\n",
    "    #\n",
    "    # robot.Q, or robot.QEst ??\n",
    "    Innov = z-xLandmark # LOOKS GOOD # Innovation\n",
    "    Innov[1] = AngleWrap(Innov[1])\n",
    "    S = jH@PPred@jH.T + robot.Q\n",
    "    K = PPred@jH@linalg.inv(S) # LOOKS GOOD # 3. Gain\n",
    "    robot.xEst = xPred + K@Innov # 4. Map estimation    \n",
    "    robot.PEst = (np.eye(robot.PEst.shape[0]) - K@jH)@PPred\n",
    "    #robot.PEst = PPred - K@S@K.T # Alternative way\n",
    "    \n",
    "    #ensure P remains symmetric\n",
    "    robot.PEst = 0.5*(robot.PEst+robot.PEst.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Putting all together in the EKF algorithm</i></b></span>** \n",
    "\n",
    "Now that you have implemented the building blocks of the EKF filter for mapping the **<span style=\"color:seagreen\">Nirvana shopping mall</span>**, it is time to write a simple function ``EKFMapping()`` putting them together. For that, **you have to** call each method with the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EKFMapping(robot: EFKMappingRobot, z, iLandmark):\n",
    "    \"\"\" EFK algorithm for mapping\n",
    "        \n",
    "            robot: Robot base (contains state map: xEst, PEst)\n",
    "            z: Observation of a landmark\n",
    "            iLandmark: Index of z in the world map\n",
    "    \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Do prediction step\n",
    "    [xPred, PPred] = prediction_step(robot)\n",
    "\n",
    "    # Check if feature observed is in map\n",
    "    if robot.MappedLandmarks[iLandmark] > -1:\n",
    "        update_step(robot, z, iLandmark, xPred, PPred)\n",
    "        \n",
    "    else:\n",
    "        # This is a new feature, so add its information to the map        \n",
    "        incorporate_new_landmark(robot, z, iLandmark, xPred, PPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 Testing the mapping system\n",
    "\n",
    "### Playing with one landmark\n",
    "\n",
    "Let's consider that the mall has only one landmark to get things started (``nLandmarks=1``). The following function provides a demo where the robot is commanded to follow a squared trajectory while observing a landmark after each movement. \n",
    "\n",
    "The **<span style=\"color:seagreen\">Nirvana</span>** managers are curious about the state and dimensions of the variables storing the estimated positions `xEst` and their associated uncertainties `Pest`, so we show their content after each 5 iterations of the algorithm. \n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-2.png\" width=\"500\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 1: Example run of the EKF algorithmn for mapping (only one landmark). <br/>\n",
    "      it shows the true pose (in red), <br/>\n",
    "      the real pose of the landmark (as a green star), <br/>\n",
    "      and the estimation from the EKF algorithm (pose and confidence ellipse).\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_ekf_mapping(robot,\n",
    "                     Map,\n",
    "                     nLandmarks,\n",
    "                     mode='non_stop',\n",
    "                     logger=None,\n",
    "                     nSteps=100, # Number of motions\n",
    "                     turning= 40, # Number of motions before turning (square path)\n",
    "                     print_each=2):\n",
    "    \n",
    "    %matplotlib widget\n",
    "    if mode == 'step_by_step':\n",
    "        matplotlib.use('TkAgg')\n",
    "\n",
    "    # storing the number of times a landmark has been seen\n",
    "    # also store the handler to the graphical info shown\n",
    "    canvas = MapCanvas(nLandmarks)\n",
    "    \n",
    "    canvas.ax.plot(Map[0, :], Map[1, :], 'g*')\n",
    "    hObsLine = canvas.ax.plot([0,0], [0,0], linestyle=':')\n",
    "    \n",
    "    # Control action\n",
    "    u = np.zeros((3, 1))\n",
    "    u[0] = (2.*MapSize/1.5)/turning\n",
    "    u[1] = 0.\n",
    "    \n",
    "    log_xEst = []\n",
    "    log_PEst = []\n",
    "    \n",
    "    # Start the loop!\n",
    "    for k in range(nSteps):\n",
    "        #\n",
    "        # Move the robot\n",
    "        #\n",
    "        u[2]=0.\n",
    "        if k%turning == turning-1:\n",
    "            u[2] = np.pi/2\n",
    "        \n",
    "        robot.step(u) # Perfectly known robot pose\n",
    "        \n",
    "        z, iLandmark = robot.get_random_observation(world=Map)\n",
    "        \n",
    "        # Update the \"observedtimes\" for the feature and plot the reading\n",
    "        canvas.increment_observed_times(iLandmark)\n",
    "        canvas.PlotNumberOfReadings(robot.true_pose, iLandmark, Map)\n",
    "        \n",
    "        EKFMapping(robot, z, iLandmark)\n",
    "        \n",
    "        # Store map evolution each 5 steps\n",
    "        if not k%5:\n",
    "            log_xEst.append(robot.xEst)\n",
    "            log_PEst.append(robot.PEst)\n",
    "        \n",
    "        # Log important values\n",
    "        if logger is not None:\n",
    "            logger.log(k, robot, Map)\n",
    "        \n",
    "        # Drawings\n",
    "        if k%print_each == print_each-1:\n",
    "            DrawRobot(canvas.fig, canvas.ax,robot.true_pose, 'r')#plot(xVehicleTrue(1),xVehicleTrue(2),'r*')\n",
    "            canvas.DoMapGraphics(robot) # Draw estimated poitns (in black) and ellipses\n",
    "            plt.axis([-MapSize-5, MapSize+5, -MapSize-5, MapSize+5]) # Set limits again\n",
    "            #plt.draw()\n",
    "#           plt.savefig(str(k)+'.jpg')\n",
    "            clear_output(wait=True)\n",
    "            display(canvas.fig) \n",
    "            \n",
    "            if mode == 'step_by_step':\n",
    "                plt.waitforbuttonpress(-1)\n",
    "            elif mode == 'visualize_process':\n",
    "                time.sleep(0.2)\n",
    "            elif mode == 'non_stop':\n",
    "                pass # non stop!\n",
    "\n",
    "    # Final drawings\n",
    "    %matplotlib inline\n",
    "    if logger is not None:\n",
    "        logger.plot()\n",
    "    \n",
    "    # Print map evolution each 5 steps\n",
    "    for i in range(0,len(log_xEst)):\n",
    "        with np.printoptions(precision=3):\n",
    "            print('Iteration: ' + str(i*5))\n",
    "            print('Estimated xEst:\\n' + str(log_xEst[i]))\n",
    "            print('Estimated PEst:\\n' + str(log_PEst[i]))\n",
    "            print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'pow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m robot \u001b[39m=\u001b[39m EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output \u001b[39m# ADDED BECAUSE OF AN ERROR\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m demo_ekf_mapping(robot, Map ,nLandmarks, mode\u001b[39m=\u001b[39;49mmode)\n",
      "Cell \u001b[1;32mIn [12], line 40\u001b[0m, in \u001b[0;36mdemo_ekf_mapping\u001b[1;34m(robot, Map, nLandmarks, mode, logger, nSteps, turning, print_each)\u001b[0m\n\u001b[0;32m     36\u001b[0m     u[\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     38\u001b[0m robot\u001b[39m.\u001b[39mstep(u) \u001b[39m# Perfectly known robot pose\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m z, iLandmark \u001b[39m=\u001b[39m robot\u001b[39m.\u001b[39;49mget_random_observation(world\u001b[39m=\u001b[39;49mMap)\n\u001b[0;32m     42\u001b[0m \u001b[39m# Update the \"observedtimes\" for the feature and plot the reading\u001b[39;00m\n\u001b[0;32m     43\u001b[0m canvas\u001b[39m.\u001b[39mincrement_observed_times(iLandmark)\n",
      "Cell \u001b[1;32mIn [2], line 48\u001b[0m, in \u001b[0;36mEFKMappingRobot.get_random_observation\u001b[1;34m(self, world, noisy)\u001b[0m\n\u001b[0;32m     46\u001b[0m iLandmarks \u001b[39m=\u001b[39m world\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     47\u001b[0m iLandmark \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(iLandmarks)\n\u001b[1;32m---> 48\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobserve(iLandmark, world, noisy)\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m z, [iLandmark]\n",
      "Cell \u001b[1;32mIn [2], line 35\u001b[0m, in \u001b[0;36mEFKMappingRobot.observe\u001b[1;34m(self, idx, world, noisy)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m# Range\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# z[0, :] = np.sqrt(np.sum(delta**2)) # OVERFLOW HERE??\u001b[39;00m\n\u001b[0;32m     34\u001b[0m z[\u001b[39m0\u001b[39m, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mpower(delta, \u001b[39m2\u001b[39m))) \u001b[39m# np.power???\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m np\u001b[39m.\u001b[39;49mpow\n\u001b[0;32m     36\u001b[0m \u001b[39m# Bearing\u001b[39;00m\n\u001b[0;32m     37\u001b[0m z[\u001b[39m1\u001b[39m, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marctan2(delta[\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m],delta[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrue_pose[\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\javie\\git\\uma_robotics_2023\\robotica\\lib\\site-packages\\numpy\\__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 311\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'pow'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ea6215944c436f8d60585a7fa0cd85",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAokElEQVR4nO3de3TU9Z3/8dcEJpMEGAiXJFwGCNYjolIwCI2oqxgSPfRsqRzcLmiFzS9UDS0YTsWsFoJrRS7irSjQ1UhVFg7l9IJVSRZb7C7hFopy0ahHKZSYoCtkWCKTIfn8/vBkumO4Zr7MJZ/n4xxPnc98J7zzhurTSb7gMsYYAQAAwBpJsR4AAAAA0UUAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAynWM9wKXQ0tKi2tpadevWTS6XK9bjAAAAOMoYoxMnTqhfv35KSrr49/M6ZADW1tbK5/PFegwAAIBL6vDhwxowYMBFv65DBmC3bt0kfb0Ur9cb42nOLBgMqqKiQvn5+XK73bEeJyGxQ2ewx8ixQ2ewR2ewx8glwg79fr98Pl+oeS5WhwzA1i/7er3euA7AtLQ0eb3euP3FFe/YoTPYY+TYoTPYozPYY+QSaYft/VY3bgIBAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsE5MAPHLkiO666y716tVLqampuuaaa7Rr167Q88YYzZs3T3379lVqaqry8vL00UcfxWJUAACADifqAXjs2DGNHTtWbrdbb775pg4cOKAnn3xS6enpoWsWL16sZ599VitWrND27dvVpUsXFRQU6NSpU9EeFwAAoMPpHO0fcNGiRfL5fCovLw+dZWdnh/7eGKOnn35ajzzyiL73ve9Jkn71q18pMzNTv/3tb/WDH/wg2iMDAAB0KFEPwN///vcqKCjQ5MmTtWXLFvXv31/333+/ioqKJEmffvqp6urqlJeXF3pN9+7dNWbMGFVVVZ0xAAOBgAKBQOix3++XJAWDQQWDwUv8GbVP61zxOl8iYIfOYI+RY4fOYI/OYI+RS4QdRjqbyxhjHJrlgqSkpEiSSkpKNHnyZO3cuVOzZs3SihUrdM8992jr1q0aO3asamtr1bdv39Dr7rzzTrlcLq1bt67NxywrK9OCBQvanK9Zs0ZpaWmX7pMBAACIgcbGRk2ZMkUNDQ3yer0X/fqoB2BycrJGjRqlrVu3hs5+8pOfaOfOnaqqqmpXAJ7pHUCfz6cvvviiXUuJhmAwqMrKSo0fP15utzvW4yQkdugM9hg5dugM9ugM9hi5RNih3+9X79692x2AUf8ScN++fTVs2LCwsyuvvFIbNmyQJGVlZUmS6uvrwwKwvr5eI0aMOOPH9Hg88ng8bc7dbnfc/sS1SoQZ4x07dAZ7jBw7dAZ7dAZ7jFw87zDSuaJ+F/DYsWNVU1MTdvbhhx9q0KBBkr6+ISQrK0ubN28OPe/3+7V9+3bl5uZGdVYAAICOKOrvAD7wwAO6/vrr9fjjj+vOO+/Ujh07tGrVKq1atUqS5HK5NHv2bD322GO6/PLLlZ2drZ/97Gfq16+fJk6cGO1xAQAAOpyoB+B1112n3/zmNyotLdWjjz6q7OxsPf3005o6dWromgcffFAnT57UjBkzdPz4cd1www166623QjeQAAAAoP2iHoCS9N3vflff/e53z/q8y+XSo48+qkcffTSKUwEAANiBPwsYAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZWIagE888YRcLpdmz54dOjt16pSKi4vVq1cvde3aVZMmTVJ9fX3shgQAAOhgYhaAO3fu1MqVKzV8+PCw8wceeEAbN27U+vXrtWXLFtXW1uqOO+6I0ZQAAAAdT0wC8H//9381depU/fKXv1R6enrovKGhQS+++KKWLVumcePGKScnR+Xl5dq6dau2bdsWi1EBAAA6nM6x+EGLi4s1YcIE5eXl6bHHHgudV1dXKxgMKi8vL3Q2dOhQDRw4UFVVVfrOd75zxo8XCAQUCARCj/1+vyQpGAwqGAxeos8iMq1zxet8iYAdOoM9Ro4dOoM9OoM9Ri4RdhjpbFEPwLVr12r37t3auXNnm+fq6uqUnJysHj16hJ1nZmaqrq7urB9z4cKFWrBgQZvziooKpaWlRTzzpVRZWRnrERIeO3QGe4wcO3QGe3QGe4xcPO+wsbExotdHNQAPHz6sWbNmqbKyUikpKY593NLSUpWUlIQe+/1++Xw+5efny+v1OvbjOCkYDKqyslLjx4+X2+2O9TgJiR06gz1Gjh06gz06gz1GLhF22PrVzvaKagBWV1fr6NGjuvbaa0Nnzc3Neuedd/SLX/xCmzZtUlNTk44fPx72LmB9fb2ysrLO+nE9Ho88Hk+bc7fbHbc/ca0SYcZ4xw6dwR4jxw6dwR6dwR4jF887jHSuqAbgrbfeqr1794adTZ8+XUOHDtXcuXPl8/nkdru1efNmTZo0SZJUU1OjQ4cOKTc3N5qjAgAAdFhRDcBu3brp6quvDjvr0qWLevXqFTovLCxUSUmJevbsKa/Xqx//+MfKzc096w0gAAAAuDgxuQv4XJ566iklJSVp0qRJCgQCKigo0PPPPx/rsQAAADqMmAfgn/70p7DHKSkpWr58uZYvXx6bgQAAADo4/ixgAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAlol6AC5cuFDXXXedunXrpoyMDE2cOFE1NTVh15w6dUrFxcXq1auXunbtqkmTJqm+vj7aowIAAHRIUQ/ALVu2qLi4WNu2bVNlZaWCwaDy8/N18uTJ0DUPPPCANm7cqPXr12vLli2qra3VHXfcEe1RAQAAOqTO0f4B33rrrbDHL7/8sjIyMlRdXa2bbrpJDQ0NevHFF7VmzRqNGzdOklReXq4rr7xS27Zt03e+851ojwwAANChRD0Av6mhoUGS1LNnT0lSdXW1gsGg8vLyQtcMHTpUAwcOVFVV1RkDMBAIKBAIhB77/X5JUjAYVDAYvJTjt1vrXPE6XyJgh85gj5Fjh85gj85gj5FLhB1GOpvLGGMcmuWitbS06B//8R91/Phx/dd//Zckac2aNZo+fXpY0EnS6NGjdcstt2jRokVtPk5ZWZkWLFjQ5nzNmjVKS0u7NMMDAADESGNjo6ZMmaKGhgZ5vd6Lfn1M3wEsLi7Wvn37QvHXXqWlpSopKQk99vv98vl8ys/Pb9dSoiEYDKqyslLjx4+X2+2O9TgJiR06gz1Gjh06gz06gz1GLhF22PrVzvaKWQDOnDlTr7/+ut555x0NGDAgdJ6VlaWmpiYdP35cPXr0CJ3X19crKyvrjB/L4/HI4/G0OXe73XH7E9cqEWaMd+zQGewxcuzQGezRGewxcvG8w0jnivpdwMYYzZw5U7/5zW/09ttvKzs7O+z5nJwcud1ubd68OXRWU1OjQ4cOKTc3N9rjAgAAdDhRfwewuLhYa9as0e9+9zt169ZNdXV1kqTu3bsrNTVV3bt3V2FhoUpKStSzZ095vV79+Mc/Vm5uLncAAwAAOCDqAfjCCy9Ikm6++eaw8/Lyck2bNk2S9NRTTykpKUmTJk1SIBBQQUGBnn/++ShPCgAA0DFFPQAv5KbjlJQULV++XMuXL4/CRAAAAHbhzwIGAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgmbgNwOXLl2vw4MFKSUnRmDFjtGPHjliPBAAA0CHEZQCuW7dOJSUlmj9/vnbv3q1vf/vbKigo0NGjR2M9GgAAQMKLywBctmyZioqKNH36dA0bNkwrVqxQWlqaXnrppViPBgAAkPA6x3qAb2pqalJ1dbVKS0tDZ0lJScrLy1NVVdUZXxMIBBQIBEKP/X6/JCkYDCoYDF7agdupda54nS8RsENnsMfIsUNnsEdnsMfIJcIOI53NZYwxDs3iiNraWvXv319bt25Vbm5u6PzBBx/Uli1btH379javKSsr04IFC9qcr1mzRmlpaZd0XgAAgGhrbGzUlClT1NDQIK/Xe9Gvj7t3ANujtLRUJSUlocd+v18+n0/5+fntWko0BINBVVZWavz48XK73bEeJyGxQ2ewx8ixQ2ewR2ewx8glwg5bv9rZXnEXgL1791anTp1UX18fdl5fX6+srKwzvsbj8cjj8bQ5d7vdcfsT1yoRZox37NAZ7DFy7NAZ7NEZ7DFy8bzDSOeKu5tAkpOTlZOTo82bN4fOWlpatHnz5rAvCQMAAKB94u4dQEkqKSnRPffco1GjRmn06NF6+umndfLkSU2fPj3WowEAACS8uAzAf/qnf9Lnn3+uefPmqa6uTiNGjNBbb72lzMzMWI8GAACQ8OIyACVp5syZmjlzZqzHAAAA6HDi7nsAAQAAcGkRgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCEftqt2lcavHaVftrliPAgAAzoIAhKN+9e6v9MeDf9Qr774S61EAAMBZdI71AEh8fz3+V33R+IVcLpfW7V8nSVq7f63uGXGPjDHqndZbg3oMivGUAACgFQGIiA1+ZnDo711ySZI+P/m5clblhM7NfBPtsQAAwFnwJWBE7NXvv6rOSV//t4SRCfvfzkmd9er3X43ZbAAAoK2oBuDBgwdVWFio7Oxspaam6rLLLtP8+fPV1NQUdt17772nG2+8USkpKfL5fFq8eHE0x8RFmjp8qrb/v+1nfG77/9uuqcOnRnkiAABwLlH9EvAHH3yglpYWrVy5Ut/61re0b98+FRUV6eTJk1q6dKkkye/3Kz8/X3l5eVqxYoX27t2rf/mXf1GPHj00Y8aMaI6LdkhSklrUEvpfAAAQf6IagLfddptuu+220OMhQ4aopqZGL7zwQigAX3vtNTU1Nemll15ScnKyrrrqKu3Zs0fLli0jAONYRpcMZXXNks/rU+HIQr34lxd12H9YGV0yYj0aAAD4hpjfBNLQ0KCePXuGHldVVemmm25ScnJy6KygoECLFi3SsWPHlJ6e3uZjBAIBBQKB0GO/3y9JCgaDCgaDl3D69mudK17nu1iZqZn66P6PlNwpWS6XS9OHT1dTc5M8nT2X7HPsaDuMFfYYOXboDPboDPYYuUTYYaSzuYwxMbs98+OPP1ZOTo6WLl2qoqIiSVJ+fr6ys7O1cuXK0HUHDhzQVVddpQMHDujKK69s83HKysq0YMGCNudr1qxRWlrapfsEAAAAYqCxsVFTpkxRQ0ODvF7vRb/ekXcAH3roIS1atOic17z//vsaOnRo6PGRI0d02223afLkyaH4a6/S0lKVlJSEHvv9fvl8PuXn57drKdEQDAZVWVmp8ePHy+12x3qchMQOncEeI8cOncEencEeI5cIO2z9amd7ORKAc+bM0bRp0855zZAhQ0J/X1tbq1tuuUXXX3+9Vq1aFXZdVlaW6uvrw85aH2dlZZ3xY3s8Hnk8njbnbrc7bn/iWiXCjPGOHTqDPUaOHTqDPTqDPUYunncY6VyOBGCfPn3Up0+fC7r2yJEjuuWWW5STk6Py8nIlJYX/TjS5ubl6+OGHFQwGQ59cZWWlrrjiijN+/x8AAAAuTlR/H8AjR47o5ptv1sCBA7V06VJ9/vnnqqurU11dXeiaKVOmKDk5WYWFhdq/f7/WrVunZ555JuxLvAAAAGi/qN4FXFlZqY8//lgff/yxBgwYEPZc670o3bt3V0VFhYqLi5WTk6PevXtr3rx5/BYwAAAADolqAE6bNu283ysoScOHD9ef//znSz8QAACAhfizgAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACwTswAMBAIaMWKEXC6X9uzZE/bce++9pxtvvFEpKSny+XxavHhxbIYEAADogGIWgA8++KD69evX5tzv9ys/P1+DBg1SdXW1lixZorKyMq1atSoGUwIAAHQ8nWPxg7755puqqKjQhg0b9Oabb4Y999prr6mpqUkvvfSSkpOTddVVV2nPnj1atmyZZsyYEYtxAQAAOpSovwNYX1+voqIivfLKK0pLS2vzfFVVlW666SYlJyeHzgoKClRTU6Njx45Fc1QAAIAOKarvABpjNG3aNN17770aNWqUDh482Oaauro6ZWdnh51lZmaGnktPT2/zmkAgoEAgEHrs9/slScFgUMFg0MHPwDmtc8XrfImAHTqDPUaOHTqDPTqDPUYuEXYY6WyOBOBDDz2kRYsWnfOa999/XxUVFTpx4oRKS0ud+GFDFi5cqAULFrQ5r6ioOOO7jPGksrIy1iMkPHboDPYYOXboDPboDPYYuXjeYWNjY0SvdxljTKRDfP755/qf//mfc14zZMgQ3Xnnndq4caNcLlfovLm5WZ06ddLUqVO1evVq/fCHP5Tf79dvf/vb0DV//OMfNW7cOH355ZcX/A6gz+fTF198Ia/XG+mnd0kEg0FVVlZq/PjxcrvdsR4nIbFDZ7DHyLFDZ7BHZ7DHyCXCDv1+v3r37q2GhoZ2tY4j7wD26dNHffr0Oe91zz77rB577LHQ49raWhUUFGjdunUaM2aMJCk3N1cPP/ywgsFgaOmVlZW64oorzhh/kuTxeOTxeNqcu93uuP2Ja5UIM8Y7dugM9hg5dugM9ugM9hi5eN5hpHNF9XsABw4cGPa4a9eukqTLLrtMAwYMkCRNmTJFCxYsUGFhoebOnat9+/bpmWee0VNPPRXNUQEAADqsmPw2MOfSvXt3VVRUqLi4WDk5Oerdu7fmzZvHbwEDAADgkJgG4ODBg3Wmb0EcPny4/vznP8dgIgAAgI6PPwsYAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwDAEIAABgGQIQAADAMgQgAACAZaIegH/4wx80ZswYpaamKj09XRMnTgx7/tChQ5owYYLS0tKUkZGhn/70pzp9+nS0xwQAAOiwOkfzB9uwYYOKior0+OOPa9y4cTp9+rT27dsXer65uVkTJkxQVlaWtm7dqs8++0w//OEP5Xa79fjjj0dzVAAAgA4ragF4+vRpzZo1S0uWLFFhYWHofNiwYaG/r6io0IEDB/Sf//mfyszM1IgRI/Rv//Zvmjt3rsrKypScnBytcQEAADqsqH0JePfu3Tpy5IiSkpI0cuRI9e3bV7fffnvYO4BVVVW65pprlJmZGTorKCiQ3+/X/v37ozUqAABAhxa1dwA/+eQTSVJZWZmWLVumwYMH68knn9TNN9+sDz/8UD179lRdXV1Y/EkKPa6rqzvrxw4EAgoEAqHHfr9fkhQMBhUMBp3+VBzROle8zpcI2KEz2GPk2KEz2KMz2GPkEmGHkc4WcQA+9NBDWrRo0Tmvef/999XS0iJJevjhhzVp0iRJUnl5uQYMGKD169frRz/6UbtnWLhwoRYsWNDmvKKiQmlpae3+uNFQWVkZ6xESHjt0BnuMHDt0Bnt0BnuMXDzvsLGxMaLXRxyAc+bM0bRp0855zZAhQ/TZZ59JCv+eP4/HoyFDhujQoUOSpKysLO3YsSPstfX19aHnzqa0tFQlJSWhx36/Xz6fT/n5+fJ6vRf1+URLMBhUZWWlxo8fL7fbHetxEhI7dAZ7jBw7dAZ7dAZ7jFwi7LD1q53tFXEA9unTR3369DnvdTk5OfJ4PKqpqdENN9wg6esFHzx4UIMGDZIk5ebm6uc//7mOHj2qjIwMSV/Xt9frDQvHb/J4PPJ4PG3O3W533P7EtUqEGeMdO3QGe4wcO3QGe3QGe4xcPO8w0rmi9j2AXq9X9957r+bPny+fz6dBgwZpyZIlkqTJkydLkvLz8zVs2DDdfffdWrx4serq6vTII4+ouLj4jIEHAACAixfV3wdwyZIl6ty5s+6++2599dVXGjNmjN5++22lp6dLkjp16qTXX39d9913n3Jzc9WlSxfdc889evTRR6M5JgAAQIcW1QB0u91aunSpli5detZrBg0apDfeeCOKUwEAANiFPwsYAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGAZAhAAAMAyBCAAAIBlCEAAAADLEIAAAACWIQABAAAsQwACAABYhgAEAACwTOdYD3ApGGMkSX6/P8aTnF0wGFRjY6P8fr/cbnesx0lI7NAZ7DFy7NAZ7NEZ7DFyibDD1sZpbZ6L1SED8MSJE5Ikn88X40kAAAAunRMnTqh79+4X/TqXaW86xrGWlhbV1taqW7ducrlcsR7njPx+v3w+nw4fPiyv1xvrcRISO3QGe4wcO3QGe3QGe4xcIuzQGKMTJ06oX79+Skq6+O/o65DvACYlJWnAgAGxHuOCeL3euP3FlSjYoTPYY+TYoTPYozPYY+TifYfteeevFTeBAAAAWIYABAAAsAwBGCMej0fz58+Xx+OJ9SgJix06gz1Gjh06gz06gz1GzoYddsibQAAAAHB2vAMIAABgGQIQAADAMgQgAACAZQhAAAAAyxCAMfKHP/xBY8aMUWpqqtLT0zVx4sSw5w8dOqQJEyYoLS1NGRkZ+ulPf6rTp0/HZtg4FggENGLECLlcLu3Zsyfsuffee0833nijUlJS5PP5tHjx4tgMGacOHjyowsJCZWdnKzU1VZdddpnmz5+vpqamsOvY4/ktX75cgwcPVkpKisaMGaMdO3bEeqS4tXDhQl133XXq1q2bMjIyNHHiRNXU1IRdc+rUKRUXF6tXr17q2rWrJk2apPr6+hhNnBieeOIJuVwuzZ49O3TGHs/vyJEjuuuuu9SrVy+lpqbqmmuu0a5du0LPG2M0b9489e3bV6mpqcrLy9NHH30Uw4mdQwDGwIYNG3T33Xdr+vTpevfdd/Xf//3fmjJlSuj55uZmTZgwQU1NTdq6datWr16tl19+WfPmzYvh1PHpwQcfVL9+/dqc+/1+5efna9CgQaqurtaSJUtUVlamVatWxWDK+PTBBx+opaVFK1eu1P79+/XUU09pxYoV+td//dfQNezx/NatW6eSkhLNnz9fu3fv1re//W0VFBTo6NGjsR4tLm3ZskXFxcXatm2bKisrFQwGlZ+fr5MnT4aueeCBB7Rx40atX79eW7ZsUW1tre64444YTh3fdu7cqZUrV2r48OFh5+zx3I4dO6axY8fK7XbrzTff1IEDB/Tkk08qPT09dM3ixYv17LPPasWKFdq+fbu6dOmigoICnTp1KoaTO8QgqoLBoOnfv7/593//97Ne88Ybb5ikpCRTV1cXOnvhhReM1+s1gUAgGmMmhDfeeMMMHTrU7N+/30gyf/nLX0LPPf/88yY9PT1sX3PnzjVXXHFFDCZNHIsXLzbZ2dmhx+zx/EaPHm2Ki4tDj5ubm02/fv3MwoULYzhV4jh69KiRZLZs2WKMMeb48ePG7Xab9evXh655//33jSRTVVUVqzHj1okTJ8zll19uKisrzT/8wz+YWbNmGWPY44WYO3euueGGG876fEtLi8nKyjJLliwJnR0/ftx4PB7zH//xH9EY8ZLiHcAo2717t44cOaKkpCSNHDlSffv21e233659+/aFrqmqqtI111yjzMzM0FlBQYH8fr/2798fi7HjTn19vYqKivTKK68oLS2tzfNVVVW66aablJycHDorKChQTU2Njh07Fs1RE0pDQ4N69uwZeswez62pqUnV1dXKy8sLnSUlJSkvL09VVVUxnCxxNDQ0SFLo1111dbWCwWDYTocOHaqBAwey0zMoLi7WhAkTwvYlsccL8fvf/16jRo3S5MmTlZGRoZEjR+qXv/xl6PlPP/1UdXV1YTvs3r27xowZ0yF2SABG2SeffCJJKisr0yOPPKLXX39d6enpuvnmm/Xll19Kkurq6sLiT1LocV1dXXQHjkPGGE2bNk333nuvRo0adcZr2OHF+/jjj/Xcc8/pRz/6UeiMPZ7bF198oebm5jPuiP2cX0tLi2bPnq2xY8fq6quvlvT1r6vk5GT16NEj7Fp22tbatWu1e/duLVy4sM1z7PH8PvnkE73wwgu6/PLLtWnTJt133336yU9+otWrV0v6+z/jOur/vwlAhzz00ENyuVzn/Kv1e64k6eGHH9akSZOUk5Oj8vJyuVwurV+/PsafRWxd6A6fe+45nThxQqWlpbEeOS5d6B7/ryNHjui2227T5MmTVVRUFKPJYZvi4mLt27dPa9eujfUoCefw4cOaNWuWXnvtNaWkpMR6nITU0tKia6+9Vo8//rhGjhypGTNmqKioSCtWrIj1aFHROdYDdBRz5szRtGnTznnNkCFD9Nlnn0mShg0bFjr3eDwaMmSIDh06JEnKyspqcxdh651bWVlZDk4dXy50h2+//baqqqra/BmNo0aN0tSpU7V69WplZWW1udvNhh1KF77HVrW1tbrlllt0/fXXt7m5w+Y9XojevXurU6dOZ9wR+zm3mTNn6vXXX9c777yjAQMGhM6zsrLU1NSk48ePh717xU7DVVdX6+jRo7r22mtDZ83NzXrnnXf0i1/8Qps2bWKP59G3b9+wfxdL0pVXXqkNGzZI+vs/4+rr69W3b9/QNfX19RoxYkTU5rxkYv1NiLZpaGgwHo8n7CaQpqYmk5GRYVauXGmM+ftNIPX19aFrVq5cabxerzl16lTUZ443f/3rX83evXtDf23atMlIMr/+9a/N4cOHjTF/v3mhqakp9LrS0lJuXviGv/3tb+byyy83P/jBD8zp06fbPM8ez2/06NFm5syZocfNzc2mf//+3ARyFi0tLaa4uNj069fPfPjhh22eb7154de//nXo7IMPPuDmhW/w+/1h/xzcu3evGTVqlLnrrrvM3r172eMF+Od//uc2N4HMnj3b5ObmGmP+fhPI0qVLQ8+3/ju8I9wEQgDGwKxZs0z//v3Npk2bzAcffGAKCwtNRkaG+fLLL40xxpw+fdpcffXVJj8/3+zZs8e89dZbpk+fPqa0tDTGk8enTz/9tM1dwMePHzeZmZnm7rvvNvv27TNr1641aWlpocjG1/H3rW99y9x6663mb3/7m/nss89Cf7Vij+e3du1a4/F4zMsvv2wOHDhgZsyYYXr06BF2Fz/+7r777jPdu3c3f/rTn8J+zTU2Noauuffee83AgQPN22+/bXbt2mVyc3ND/1LG2f3fu4CNYY/ns2PHDtO5c2fz85//3Hz00UfmtddeM2lpaebVV18NXfPEE0+YHj16mN/97nfmvffeM9/73vdMdna2+eqrr2I4uTMIwBhoamoyc+bMMRkZGaZbt24mLy/P7Nu3L+yagwcPmttvv92kpqaa3r17mzlz5phgMBijiePbmQLQGGPeffddc8MNNxiPx2P69+9vnnjiidgMGKfKy8uNpDP+9X+xx/N77rnnzMCBA01ycrIZPXq02bZtW6xHiltn+zVXXl4euuarr74y999/v0lPTzdpaWnm+9//fth/mODMvhmA7PH8Nm7caK6++mrj8XjM0KFDzapVq8Keb2lpMT/72c9MZmam8Xg85tZbbzU1NTUxmtZZLmOMifrXnQEAABAz3AUMAABgGQIQAADAMgQgAACAZQhAAAAAyxCAAAAAliEAAQAALEMAAgAAWIYABAAAsAwBCAAAYBkCEAAAwDIEIAAAgGUIQAAAAMsQgAAAAJYhAAEAACxDAAIAAFiGAAQAALAMAQgAAGCZ/w89KoKpFLkcQwAAAABJRU5ErkJggg==",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 1\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 8*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "from IPython.display import clear_output # ADDED BECAUSE OF AN ERROR\n",
    "demo_ekf_mapping(robot, Map ,nLandmarks, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering a larger number of landmarks \n",
    "\n",
    "Once our EKF implementation is working with one landmark, let's try it in a scenario with 5 landmarks. Again, the content of the `xEst` and `Pest` is shown after each 5 iterations of the algorithm.\n",
    "    \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-3.png\" width=\"500\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 2: Execution of the EKF algorithmn for mapping (multiple landmarks). <br/>\n",
    "      Same as in Fig 1., each landmark is accompanied by a number of times observed.\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "demo_ekf_mapping(robot, Map ,nLandmarks, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Having completed these trials, you will be able to **answer the following questions**:\n",
    "\n",
    "In the **one landmark** case:\n",
    "\n",
    "- Discuss the evolution of the variables `xEst` and `Pest`, including their dimensions.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "In the **five landmarks** case:\n",
    "\n",
    "- Why and how the content of the variables `xEst` and `Pest` has change? Discuss their size.\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- What structure does the matrix of covariances have? Is there any kind of correlation among the observations of different landmarks?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting performance results\n",
    "\n",
    "As is normal, the contracting company requires some information about how well our EFK implementation performs. For that, your colleagues have implemented a logger, which is meant to store some information each loop regarding the method performance and plot it at the end of its execution. **Execute the following code cells and take a look at that plots!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Logger():\n",
    "    \"\"\" Logs info about the covariance and error of a map.\n",
    "    \n",
    "        Attrs:\n",
    "            n_features: Number of features in the world.\n",
    "            log_error: Matrix to store the error in the fitting for each landmark.\n",
    "            log_det: Matrix to store the determinant of the covariance matrix for each landmark.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_steps, n_features):\n",
    "        \"\"\" Initializes each matrix to log the information\n",
    "        \n",
    "            Args:\n",
    "                n_steps: Maximum number of steps our robot will take.\n",
    "                n_features: Number of features in the world.\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.log_error = np.empty((n_steps,n_features))\n",
    "        self.log_det = np.empty((n_steps,n_features))\n",
    "            \n",
    "    def log(self, k: int, robot: EFKMappingRobot, Map: np.ndarray):\n",
    "        \"\"\" Computes relevant info about the error and covariances.\n",
    "        \n",
    "            It is called once per loop in the demo.\n",
    "        \n",
    "            Args:\n",
    "                k: Number of iteration we are at. Range: [0, n_steps)\n",
    "                robot: \n",
    "                Map:\n",
    "        \"\"\"\n",
    "        for idx in range(self.n_features):\n",
    "            tid = robot.MappedLandmarks[idx,0]\n",
    "            if tid <= -1:\n",
    "                self.log_error[k,idx]= np.Inf\n",
    "                self.log_det[k,idx]=np.Inf\n",
    "            else:\n",
    "                self.log_det[k,idx] = np.linalg.det(robot.PEst[tid:tid+2,tid:tid+2])\n",
    "                self.log_error[k,idx] = np.sqrt(np.sum((robot.xEst[tid:tid+2,0] - Map[:,idx])**2))\n",
    "                \n",
    "    def plot(self):\n",
    "        \"\"\" Plot all relevant figures. It is called at the end of the demo\"\"\"\n",
    "        fig1 , ax1 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2 , ax2 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2.tight_layout()\n",
    "        fig1.tight_layout()\n",
    "\n",
    "        df1 = pd.DataFrame(data= self.log_error, columns = ['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax1.set_title('Error between map and est')\n",
    "        df1.plot(ax = ax1)\n",
    "        df2 = pd.DataFrame(data=np.log(self.log_det), columns=['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax2.set_title('Det. of covar.')\n",
    "        df2.plot(ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nLandmarks = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nLandmarks)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nLandmarks)\n",
    "\n",
    "nSteps=100\n",
    "logger = Logger(n_features=nLandmarks, n_steps=nSteps)\n",
    "\n",
    "demo_ekf_mapping(robot,\n",
    "                 Map,\n",
    "                 nLandmarks,\n",
    "                 logger=logger,\n",
    "                 mode='non_stop',\n",
    "                 nSteps=nSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Having taken a look at the logger and its output, you will be able to **answer the following questions**:\n",
    "\n",
    "- What information is shown in the figures produced by the logger?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- The information about the error and the determinant of the covariance is provided for first time at different iterations of the algorithm for each landmark. Is that an error? Why is this happening?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- The error associated to each landmark not always decreases with new observations. Why could this happen?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- On the contrary, the determinant of the covariance matrix associated to each landmark always decreases when new observations are available. Is this an error? Why?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('robotica': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "28e9071c3a84e675c861ccac27ca2f83f0b4f889f18eee2378f13f1cc33790dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
